---
title: Big data ethics, Algorithms
author: Brett Petch
date: 2020-03-03 19:00:00
layout: category-post
categories: 
    - week-9
    - lecture
---
##### Prof. Melissa Adler

This is an extension of last week, I know alot of you have midterms and I hope you have had a chance to look at the slides and videos. Next week, we'll be talking about interviews and ethnography. We are getting DSLR cameras, iPhone kits, and podcasting kits. We'll be focusing on how to make a podcast. So, I'm bringing in grad students, and how to record, edit, interview, etc. 

We'll get to as much as we can, we're going to go over why all of this is importive, then think of quantitative studies where we collect lots of numerical data to generalize people. So we can quantify content. We can look at social network analysis: metadata, etc. and quantify those kinds of relationships. Mining twitter data, etc and using these giant chunks of data to find generalized conclusions / findings. 

Positivism = there is a knowable truth that can be understood through observation and collection of facts, concrete phenomena, measured and attribute to other things. Our truth claims of positivist kinds of studies are different than that of quantitative studies. 

### So, we generally have 2 types of analysis:
Descriptive / explanitory statistics :summaries and comparisons
Inferential / predictive statistics: draw from sample to make inferences about a population, generalizability; probability.

they're quite different. When we're thinking of analytics, etc. we are looking at predictions based on previous behaviours

### Lipold: Algorithmic Identity
A really good way to make people understand how people behave online. Identities have very little to do with ourselves, but rather what we do online. As we are using these things we are being formed and informed based on these data analytics. EG: Google Ad Personalization

Code is at the fundamental that algorithms are built in. "Code is Law", there is a sway in which code is written and becomes the land, becoming a determining factor of what we do online. I want to go back to the 18th century and look at the history of information technologies as we know them.

### Jeremy Bentham: 
Codificaton - codifying law. Old law code, codification. It was because he believed very strongly of utilitarianism. Max pleasure, min pain. He believed that everything could be codified based in utilitarian principals. Greatest happiness for the most people. He tried for all of his life to do this. The notion that code is the way we encounter information, structures / categories, all of these technologies. Produces an infrastructure. Roads, powerlines, information is trafficked on these infrastructures. And so, these algorithms are creating categories, making formulas to make things go any way a particular interest could want it to. 

So, ultimately we're interested in finding a relationship / correlation in particular:

### Relationship vs Correlation
Relationship: "A statistical relationship exists if a change in one variable (X) results in a systematic increase of another (Y)."
Correlation: "Correlation is a measure of relationship strength."

There are two ways of thinking of correlation: Strength of correlation / pos/neg.

Spurious Relationship: Appearance of a statistical relationship, when really another factor is influencing the results.

## Survey Research
Open ended are used for qualitative analysis or exploratory studies. Closed questions lend themselves to quantification and computerized scoring and analysis more easily. More surveys include both types of questions. Surveys have different purposes: Information gathering, big data studies, part of a mixed methods study, arriving at general conclusions, advancing theory. 

Types of survey formats:
Single response items, categorical responses, rating scales, likert scales.

One of the things to look at is "Are you an avid reader?"

Leading questions: Avoiding these kinds of questions that are 2 in 1. 
Response rates: Affect validity and generalizability of your findings; strategeis to maximize response rates: repeated contact, collaboration / word of mouth, incentives.

 Inter-item reliability, ask questions over and over; inter-item techniques. Repeating answer effectively. Inter-coder reliability is kind of what you're doing in a certain kind of way. You may sometimes find that you disagree. Where you come into agreement and see if they come into similar items. 

 ## Models: 
 One of the things you can do for your online activity: Create a model of how much energy your device consumes in terms of energy. Models are related to theory, sometimes used interchangably. Abstract representation of a process. Hopefully you've had a chance to hear about Kathy O'Neil; worked with hedge funds when 2007-2008 happened. Knows math like a genious, knows what is going on and how things went down. She's able to critique... If you haven't had a chance to watch that video, please do. They do the work of illustrating, demonstrating, visualizing or imitating. 

 There are certain things she wants us to pay attention to when we think about models. If you do end up looking at the model, you need to leave some information out; reduce to component parts. Encoding meaning. This is the big connection. When we create a model, algorithm, etc. we are building into it ideas, principles in itself. Models are put into a purpose and are put to work. When you encounter / create: how can it be at scale, etc. she looks at different algorithmic models for credit ratings, etc. different algorithms that look for criminality, people who are safe bets for credit, people going to university. She's interested in the ways the assumptions can in fact do damage; IE: Weapons of Math Destruction.

 ### Big Data Concepts:
 Structured Data: Formatted, organized, tabular: spreadsheets, databases, etc. 
 Unstructured Data: Unformatted, lack structure / organization: text, images, audio, video.
 Hybrid: Descriptive metadata, marked up data (XML).


### Definitions: 
Volume, Variety, Velocity, veracity, variability, value.

### Ethics, Responsible Big Data Research
- Acknowledge that data re people and can do harm
- Privacy isn't just about public / private data
- Think about the possibility of reuse / reidentification of your data
- Practice ethical data sharing
- Big does not always mean better
- Design for auditability.
- Get participants and communities involved in establishing codes of conduct.
- Consider the broader consequences.

Next thing:

## Netlytic: You have 3 choices:
Download a dataset using Netlytic (data should do something with climate change) OR visualize the data stored on your phone and consider its carbon consumption (be creative and descriptive!) or keep a photo log of carbon consumption of a data of your life.

